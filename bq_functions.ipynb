{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "SERVICE_ACCOUNT_FILE = \"./config/local/rd-multicanal-caip-prod-0ec5b75f6a1b.json\"\n",
    "credentials = \n",
    "\n",
    "def get_gcp_credentials(\n",
    "    service_account_file=\"./config/local/rd-multicanal-caip-prod-0ec5b75f6a1b.json\",\n",
    "):\n",
    "    \"\"\"Returns a credentials object to authenticate to GCP.\n",
    "    args:\n",
    "        service_account_file: path to the service account file\n",
    "    \"\"\"\n",
    "    return service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n",
    "\n",
    "\n",
    "def get_bigquery_client(credentials=credentials):\n",
    "    \"\"\"\n",
    "    Returns a BigQuery client object to make queries to GCP.\n",
    "        args:\n",
    "            credentials: GCP credentials object\n",
    "    \"\"\"\n",
    "    return bigquery.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "def list_tables(dataset_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns a list of tables in a dataset.\n",
    "        args:\n",
    "            dataset_id: name of the dataset\n",
    "            client: BigQuery client object\n",
    "        returns:\n",
    "            tables: list of tables in the dataset\n",
    "    \"\"\"\n",
    "    #dataset_ref = client.dataset(dataset_id)\n",
    "    tables = list(client.list_tables(dataset_id))\n",
    "    return tables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_table_schema(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns the schema of a table.\n",
    "        args:   dataset_id: name of the dataset\n",
    "                table_id: name of the table\n",
    "                client: BigQuery client object\n",
    "        returns: schema of the table\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    return table_obj.schema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataset_iterator(client=client):\n",
    "    \"\"\"\n",
    "    Returns an iterator over the datasets in the project.\n",
    "    args: client: BigQuery client object\n",
    "    \"\"\"\n",
    "    datasets = client.list_datasets()\n",
    "    for dataset in datasets:\n",
    "        yield dataset\n",
    "\n",
    "\n",
    "def table_iterator(dataset_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns an iterator over the tables in a dataset.\n",
    "    args:   dataset_id: name of the dataset\n",
    "            client: BigQuery client object\n",
    "    \"\"\"\n",
    "    tables = client.list_tables(dataset_id)\n",
    "    for table in tables:\n",
    "        yield table\n",
    "\n",
    "\n",
    "def field_iterator(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns an iterator over the fields in a table.\n",
    "    args:   dataset_id: name of the dataset\n",
    "            table_id: name of the table\n",
    "            client: BigQuery client object\n",
    "    returns: iterator over the fields in the table\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    for field in table_obj.schema:\n",
    "        yield field\n",
    "\n",
    "\n",
    "def dataset_table_iterator(client=client):\n",
    "    \"\"\"\n",
    "    Returns an iterator over the datasets and tables in the project.\n",
    "        args: client: BigQuery client object\n",
    "    \"\"\"\n",
    "    for dataset in dataset_iterator(client=client):\n",
    "        for table in table_iterator(dataset.dataset_id, client=client):\n",
    "            yield dataset.dataset, table.table\n",
    "\n",
    "\n",
    "def table_field_iterator(dataset_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns an iterator over the tables and fields in a dataset.\n",
    "        args:   dataset_id: name of the dataset\n",
    "                client: BigQuery client object\n",
    "    \"\"\"\n",
    "    for table in table_iterator(dataset_id, client=client):\n",
    "        for field in field_iterator(dataset_id, table.table_id, client=client):\n",
    "            yield table, field\n",
    "\n",
    "\n",
    "def dataset_table_field_iterator(client=client):\n",
    "    \"\"\"\n",
    "    Returns an iterator over the datasets, tables and fields in the project.\n",
    "        args: client: BigQuery client object\n",
    "    \"\"\"\n",
    "    for dataset in dataset_iterator(client=client):\n",
    "        for table in table_iterator(dataset.dataset_id, client=client):\n",
    "            for field in field_iterator(\n",
    "                dataset.dataset_id, table.table_id, client=client\n",
    "            ):\n",
    "                yield dataset, table, field\n",
    "\n",
    "\n",
    "def get_types(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the types of the fields in a table.\n",
    "        args:   dataset_id: name of the dataset\n",
    "                table_id: name of the table\n",
    "                client: BigQuery client object\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    types = {}\n",
    "    for field in table_obj.schema:\n",
    "        types[field.name] = field.field_type\n",
    "    return types\n",
    "\n",
    "\n",
    "def get_length(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns the number of rows in a table.\n",
    "        args:   dataset_id: name of the dataset\n",
    "                table_id: name of the table\n",
    "                client: BigQuery client object\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    return table_obj.num_rows\n",
    "\n",
    "\n",
    "get_length(\"caip\", \"comment\")\n",
    "\n",
    "\n",
    "def get_timestamp_columns(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns a list of the timestamp columns in a table.\n",
    "        args:   dataset_id: name of the dataset\n",
    "                table_id: name of the table\n",
    "                client: BigQuery client object\n",
    "    \"\"\"\n",
    "    time_cols = []\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    for field in table_obj.schema:\n",
    "        if field.field_type == \"TIMESTAMP\":\n",
    "            time_cols.append(field.name)\n",
    "    return time_cols\n",
    "\n",
    "\n",
    "def types2dict(client=client):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the types of the fields in each table.\n",
    "    args: client: BigQuery client object\n",
    "    \"\"\"\n",
    "    dtables = defaultdict(dict)\n",
    "    for dataset, table in dataset_table_iterator(client=client):\n",
    "        dtables[f\"{dataset.dataset_id}.{table.table_id}\"] = get_types(\n",
    "            dataset.dataset_id, table.table_id, client=client\n",
    "        )\n",
    "    return dtables\n",
    "\n",
    "\n",
    "def nrows2dict(client=client):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the number of rows in each table.\n",
    "    args: client: BigQuery client object\n",
    "    \"\"\"\n",
    "    dtables = defaultdict(dict)\n",
    "    for dataset, table in dataset_table_iterator(client=client):\n",
    "        dtables[f\"{dataset.dataset_id}.{table.table_id}\"] = get_length(\n",
    "            dataset.dataset_id, table.table_id, client=client\n",
    "        )\n",
    "    return dtables\n",
    "\n",
    "\n",
    "def timestamp_cols2dict(client=client):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the timestamp columns in each table.\n",
    "    args: client: BigQuery client object\n",
    "    \"\"\"\n",
    "    dtables = defaultdict(dict)\n",
    "    for dataset, table in dataset_table_iterator(client=client):\n",
    "        dtables[f\"{dataset.dataset_id}.{table.table_id}\"] = get_timestamp_columns(\n",
    "            dataset.dataset_id, table.table_id, client=client\n",
    "        )\n",
    "    return dtables\n",
    "\n",
    "\n",
    "def get_date_range(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns the minimum and maximum date in a table.\n",
    "    args:   dataset_id: name of the dataset\n",
    "            table_id: name of the table\n",
    "            client: BigQuery client object\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    query = f\"SELECT MIN(CAST({table_obj.schema[0].name} AS DATE)) AS min_date, MAX(CAST({table_obj.schema[0].name} AS DATE)) AS max_date FROM `{dataset_id}.{table_id}`\"\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_date_ranges(dataset_id, table_id, client=client, as_str=False):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the minimum and maximum date in each table.\n",
    "    args:   dataset_id: name of the dataset\n",
    "            table_id: name of the table\n",
    "            client: BigQuery client object\n",
    "            as_str: if True, returns the dates as strings\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    dtables = defaultdict(dict)\n",
    "    for dataset, table in dataset_table_iterator(client=client):\n",
    "        for field in table_obj.schema:\n",
    "            if field.field_type == \"TIMESTAMP\":\n",
    "                max_min_dates = get_date_range(\n",
    "                    dataset.dataset_id, table.table_id, client=client\n",
    "                )\n",
    "                # max_min_dates = get_time_range(dataset, table, field, client = client)\n",
    "                if as_str:\n",
    "                    max_min_dates = [time2str(i) for i in max_min_dates]\n",
    "                dtables[f\"{dataset.dataset_id}.{table.table_id}\"] = max_min_dates\n",
    "    return dtables\n",
    "\n",
    "\n",
    "def time2str(time_obj, format=\"%Y-%m-%d %H:%M:%S\"):\n",
    "    \"\"\"\n",
    "    Returns a string representation of a time object.\n",
    "    args:   time_obj: time object\n",
    "            format: format of the string representation\n",
    "    \"\"\"\n",
    "    return time_obj.strftime(format)\n",
    "\n",
    "\n",
    "def dict2df(dtables, columns=[\"type\"]):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with the types of the fields in each table.\n",
    "    args:   dtables: dictionary with the types of the fields in each table\n",
    "            columns: columns of the dataframe\n",
    "    \"\"\"\n",
    "    dftables = defaultdict(dict)\n",
    "    for k, v in dtables.items():\n",
    "        dftables[k] = pd.DataFrame.from_dict(v, orient=\"index\", columns=columns)\n",
    "    return dftables\n",
    "\n",
    "\n",
    "def get_time_range(dataset, table, field, client=client):\n",
    "    \"\"\"\n",
    "    Returns the minimum and maximum time in a field.\n",
    "    args:   dataset: dataset object\n",
    "            table: table object\n",
    "            field: field object\n",
    "            client: BigQuery client object\n",
    "\n",
    "    \"\"\"\n",
    "    return list(\n",
    "        client.query(\n",
    "            f\"SELECT min({field.field_name}), max({field.field_name}) FROM {table.table_id}\"\n",
    "        )\n",
    "        .to_dataframe()\n",
    "        .values[0]\n",
    "    )\n",
    "\n",
    "\n",
    "def write_excel(dftables, filename=\"rd-multicanal-caip-prod_column_types.xlsx\"):\n",
    "    \"\"\"\n",
    "    Writes a dictionary of dataframes to an excel file.\n",
    "    args:   dftables: dictionary of dataframes\n",
    "            filename: name of the excel file\n",
    "    \"\"\"\n",
    "    writer = pd.ExcelWriter(filename, engine=\"xlsxwriter\")\n",
    "    for table_id, table in dftables.items():\n",
    "        table.to_excel(writer, sheet_name=table_id)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def get_length(dataset_id, table_id, client=client):\n",
    "    \"\"\"\n",
    "    Returns the number of rows in a table.\n",
    "        args:   dataset_id: name of the dataset\n",
    "                table_id: name of the table\n",
    "                client: BigQuery client object\n",
    "    \"\"\"\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    return table_obj.num_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
